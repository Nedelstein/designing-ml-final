{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the dependencies\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument, TaggedLineDocument\n",
    "import gzip, os, glob\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['Donald J. Trump', 'Donald J. Trump', 'Barack Obama', 'Barack Obama', 'Barack Obama', 'Barack Obama', 'Barack Obama', 'Barack Obama', 'Barack Obama', 'Barack Obama', 'George W. Bush', 'George W. Bush', 'George W. Bush', 'George W. Bush', 'George W. Bush', 'George W. Bush', 'George W. Bush', 'George W. Bush', 'William J. Clinton', 'William J. Clinton', 'William J. Clinton', 'William J. Clinton', 'William J. Clinton', 'William J. Clinton', 'William J. Clinton', 'William J. Clinton', 'George Bush', 'George Bush', 'George Bush', 'George Bush', 'Ronald Reagan', 'Ronald Reagan', 'Ronald Reagan', 'Ronald Reagan', 'Ronald Reagan', 'Ronald Reagan', 'Ronald Reagan', 'Ronald Reagan', 'Jimmy Carter', 'Jimmy Carter', 'Jimmy Carter', 'Jimmy Carter', 'Jimmy Carter', 'Jimmy Carter', 'Jimmy Carter', 'Gerald R. Ford', 'Gerald R. Ford', 'Gerald R. Ford', 'Richard Nixon', 'Richard Nixon', 'Richard Nixon', 'Richard Nixon', 'Richard Nixon', 'Richard Nixon', 'Richard Nixon', 'Richard Nixon', 'Richard Nixon', 'Richard Nixon', 'Richard Nixon', 'Richard Nixon', 'Lyndon B. Johnson', 'Lyndon B. Johnson', 'Lyndon B. Johnson', 'Lyndon B. Johnson', 'Lyndon B. Johnson', 'Lyndon B. Johnson', 'John F. Kennedy', 'John F. Kennedy', 'John F. Kennedy', 'Dwight D. Eisenhower', 'Dwight D. Eisenhower', 'Dwight D. Eisenhower', 'Dwight D. Eisenhower', 'Dwight D. Eisenhower', 'Dwight D. Eisenhower', 'Dwight D. Eisenhower', 'Dwight D. Eisenhower', 'Dwight D. Eisenhower', 'Dwight D. Eisenhower', 'Harry S. Truman', 'Harry S. Truman', 'Harry S. Truman', 'Harry S. Truman', 'Harry S. Truman', 'Harry S. Truman', 'Harry S. Truman', 'Harry S. Truman', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Franklin D. Roosevelt', 'Herbert Hoover', 'Herbert Hoover', 'Herbert Hoover', 'Herbert Hoover', 'Calvin Coolidge', 'Calvin Coolidge', 'Calvin Coolidge', 'Calvin Coolidge', 'Calvin Coolidge', 'Calvin Coolidge', 'Warren G. Harding', 'Warren G. Harding', 'Woodrow Wilson', 'Woodrow Wilson', 'Woodrow Wilson', 'Woodrow Wilson', 'Woodrow Wilson', 'Woodrow Wilson', 'Woodrow Wilson', 'Woodrow Wilson', 'William Howard Taft', 'William Howard Taft', 'William Howard Taft', 'William Howard Taft', 'Theodore Roosevelt', 'Theodore Roosevelt', 'Theodore Roosevelt', 'Theodore Roosevelt', 'Theodore Roosevelt', 'Theodore Roosevelt', 'Theodore Roosevelt', 'Theodore Roosevelt', 'William McKinley', 'William McKinley', 'William McKinley', 'William McKinley', 'Grover Cleveland', 'Grover Cleveland', 'Grover Cleveland', 'Grover Cleveland', 'Benjamin Harrison', 'Benjamin Harrison', 'Benjamin Harrison', 'Benjamin Harrison', 'Grover Cleveland', 'Grover Cleveland', 'Grover Cleveland', 'Grover Cleveland', 'Chester A. Arthur', 'Chester A. Arthur', 'Chester A. Arthur', 'Chester A. Arthur', 'Rutherford B. Hayes', 'Rutherford B. Hayes', 'Rutherford B. Hayes', 'Rutherford B. Hayes', 'Ulysses S. Grant', 'Ulysses S. Grant', 'Ulysses S. Grant', 'Ulysses S. Grant', 'Ulysses S. Grant', 'Ulysses S. Grant', 'Ulysses S. Grant', 'Ulysses S. Grant', 'Andrew Johnson', 'Andrew Johnson', 'Andrew Johnson', 'Andrew Johnson', 'Abraham Lincoln', 'Abraham Lincoln', 'Abraham Lincoln', 'Abraham Lincoln', 'James Buchanan', 'James Buchanan', 'James Buchanan', 'James Buchanan', 'Franklin Pierce', 'Franklin Pierce', 'Franklin Pierce', 'Franklin Pierce', 'Millard Fillmore', 'Millard Fillmore', 'Millard Fillmore', 'Zachary Taylor', 'James K. Polk', 'James K. Polk', 'James K. Polk', 'James K. Polk', 'John Tyler', 'John Tyler', 'John Tyler', 'John Tyler', 'Martin van Buren', 'Martin van Buren', 'Martin van Buren', 'Martin van Buren', 'Andrew Jackson', 'Andrew Jackson', 'Andrew Jackson', 'Andrew Jackson', 'Andrew Jackson', 'Andrew Jackson', 'Andrew Jackson', 'Andrew Jackson', 'John Quincy Adams', 'John Quincy Adams', 'John Quincy Adams', 'John Quincy Adams', 'James Monroe', 'James Monroe', 'James Monroe', 'James Monroe', 'James Monroe', 'James Monroe', 'James Monroe', 'James Monroe', 'James Madison', 'James Madison', 'James Madison', 'James Madison', 'James Madison', 'James Madison', 'James Madison', 'James Madison', 'Thomas Jefferson', 'Thomas Jefferson', 'Thomas Jefferson', 'Thomas Jefferson', 'Thomas Jefferson', 'Thomas Jefferson', 'Thomas Jefferson', 'Thomas Jefferson', 'John Adams', 'John Adams', 'John Adams', 'John Adams', 'George Washington', 'George Washington', 'George Washington', 'George Washington', 'George Washington', 'George Washington', 'George Washington', 'George Washington']\n"
    }
   ],
   "source": [
    "path = '/Users/noahedelstein/Desktop/Parsons/design with ml/ml_final/ml_final_python/sotu_umap_position.json'\n",
    "\n",
    "with open(path) as data_file:\n",
    "  data = data_file.read()\n",
    "  # print(data) \n",
    "  data_content = json.loads(data)\n",
    "  # transcripts = [line['transcript'] for line in data_content]\n",
    "  # print(transcripts[0])\n",
    "  name = [line['President'] for line in data_content]\n",
    "  print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "tagged_data = []\n",
    "for i, _d in enumerate(transcripts):\n",
    "    lowercase = _d.lower()\n",
    "    remove_urls = re.sub(r\"http\\S+\", \"\", lowercase)\n",
    "    remove_punctuation = remove_urls.translate(str.maketrans('','',string.punctuation))\n",
    "    tokenized = word_tokenize(remove_punctuation)\n",
    "    words = [w for w in tokenized if not w in stop_words]\n",
    "    tagged_data.append(TaggedDocument(words=words, tags=[str(i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = RegexpTokenizer(r'/w+')\n",
    "# stopword_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@mishra.thedeepak/doc2vec-simple-implementation-example-df2afbbfbad5\n",
    "\n",
    "max_epochs = 100\n",
    "vec_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load(\"d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(\"patriot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_tags = list(model.docvecs.doctags.keys())\n",
    "X = model[doc_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "df = pd.DataFrame(X_tsne, index=doc_tags, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extracted = []\n",
    "for i, review in enumerate(transcripts):\n",
    "    features_extracted.append(model.docvecs[str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "scaled = ss.fit_transform(features_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "clusters = kmeans.fit_predict(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors=5, metric='cosine').fit(scaled)\n",
    "_, closest = neighbors.kneighbors(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, cluster_row in enumerate(closest):\n",
    "    print('\\n\\nCluster number ' + str(index) + '\\n\\n')\n",
    "    for col in cluster_row:\n",
    "        print(features_extracted[col])\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "embedding = umap.UMAP().fit_transform(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(embedding)\n",
    "embedding_scaled = scaler.transform(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path) as data_file:\n",
    "  data = data_file.read()\n",
    "#   print(data) \n",
    "  data_content = json.loads(data)\n",
    "  presidents = [line['president'] for line in data_content]\n",
    "  print(president[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = []\n",
    "\n",
    "with open(path) as data_file:\n",
    "    data = data_file.read()\n",
    "    data_content = json.loads(data)\n",
    "    transcripts = [line['transcript'] for line in data_content]\n",
    "    dates = [line['date'] for line in data_content]\n",
    "    presidents = [line['president'] for line in data_content]\n",
    "    for date, president, cluster_pos, transcript in zip(dates, presidents, embedding_scaled, transcripts):\n",
    "        lookup.append({\n",
    "            \"Date\": date,\n",
    "            \"President\": president,\n",
    "            \"Cluster_Pos\": cluster_pos.tolist(),\n",
    "            \"Speech\": transcript\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sotu_umap_position.json', 'w') as outfile:\n",
    "    json.dump(lookup, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}